2025-07-18 12:31:29,363 INFO    MainThread:38628 [wandb_setup.py:_flush():68] Current SDK version is 0.19.10
2025-07-18 12:31:29,363 INFO    MainThread:38628 [wandb_setup.py:_flush():68] Configure stats pid to 38628
2025-07-18 12:31:29,364 INFO    MainThread:38628 [wandb_setup.py:_flush():68] Loading settings from /home/matteo/.config/wandb/settings
2025-07-18 12:31:29,364 INFO    MainThread:38628 [wandb_setup.py:_flush():68] Loading settings from /home/matteo/Ricerca/miei_progetti/matformer/wandb/settings
2025-07-18 12:31:29,364 INFO    MainThread:38628 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-07-18 12:31:29,364 INFO    MainThread:38628 [wandb_init.py:setup_run_log_directory():724] Logging user logs to ./wandb/run-20250718_123129-v0ncois6/logs/debug.log
2025-07-18 12:31:29,364 INFO    MainThread:38628 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to ./wandb/run-20250718_123129-v0ncois6/logs/debug-internal.log
2025-07-18 12:31:29,366 INFO    MainThread:38628 [wandb_init.py:init():852] calling init triggers
2025-07-18 12:31:29,366 INFO    MainThread:38628 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'model_class': 'EntropyModel', 'model_config': {'name': 'Micro-Albertino', 'hidden_dim': 512, 'ffn_factor': 1.0, 'n_layers': 10, 'n_heads': 8, 'vocab_size': 32768, 'bos_id': 1, 'eos_id': 2, 'pad_id': 0, 'tie_word_embeddings': False, 'rms_norm_eps': 1e-06, 'attention_type': ['sliding'], 'sliding_window_size': 512, 'sliding_layers': [0, 2, 4, 6, 8], 'sliding_type': 'partial', 'max_seqlen': 1024, 'block_size_for_attention': 128, 'compile_flexattn': False, 'bias': False, 'training_objective': 'masked', 'alibi': True, 'is_causal': False, 'attn_impl': 'flash'}, 'training': {'lr': 0.0001, 'max_steps': 100000, 'accumulate_grad_batches': 1, 'seed': 27, 'checkpoint_name': 'micro_albertino'}, 'tokenizer': {'type': 'huggingface', 'pretrained_name': 'sapienzanlp/Minerva-350M-base-v1.0', 'varlen_strategy': 'unpadding'}, 'data': {'data_root': '../matformer_norepo/liberliber_1024_tokens', 'batch_size': 1, 'num_workers': 2}, 'save_dir': './checkpoints', 'wandb_project': 'matformer', 'wandb_run_name': 'micro-albertino-liberliber-1024-tokens', '_wandb': {}}
2025-07-18 12:31:29,366 INFO    MainThread:38628 [wandb_init.py:init():893] starting backend
2025-07-18 12:31:29,366 INFO    MainThread:38628 [wandb_init.py:init():897] sending inform_init request
2025-07-18 12:31:29,388 INFO    MainThread:38628 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-07-18 12:31:29,388 INFO    MainThread:38628 [wandb_init.py:init():907] backend started and connected
2025-07-18 12:31:29,404 INFO    MainThread:38628 [wandb_init.py:init():1002] updated telemetry
2025-07-18 12:31:29,419 INFO    MainThread:38628 [wandb_init.py:init():1026] communicating run to backend with 90.0 second timeout
2025-07-18 12:31:30,356 INFO    MainThread:38628 [wandb_init.py:init():1101] starting run threads in backend
2025-07-18 12:31:30,975 INFO    MainThread:38628 [wandb_run.py:_console_start():2566] atexit reg
2025-07-18 12:31:30,975 INFO    MainThread:38628 [wandb_run.py:_redirect():2414] redirect: wrap_raw
2025-07-18 12:31:30,976 INFO    MainThread:38628 [wandb_run.py:_redirect():2483] Wrapping output streams.
2025-07-18 12:31:30,976 INFO    MainThread:38628 [wandb_run.py:_redirect():2506] Redirects installed.
2025-07-18 12:31:30,978 INFO    MainThread:38628 [wandb_init.py:init():1147] run started, returning control to user process
2025-07-18 12:31:33,716 INFO    MainThread:38628 [wandb_run.py:_config_callback():1429] config_cb None None {'config': "ModelConfig(hidden_dim=512, ffn_factor=1.0, n_layers=10, n_heads=8, vocab_size=32768, pad_id=0, bos_id=1, eos_id=2, tie_word_embeddings=False, rms_norm_eps=1e-06, attention_type=['sliding'], sliding_window_size=512, sliding_layers=[0, 2, 4, 6, 8], sliding_type='partial', max_seqlen=1024, block_size_for_attention=128, compile_flexattn=False, bias=False, name='Micro-Albertino', training_objective='masked', is_causal=False, alibi=True, attn_impl='flash')", 'tokenizer': '<matformer.tokenizers.MatformerTokenizer object at 0x7f415f17d590>', 'device': 'cuda', 'train_config': {'lr': 0.0001, 'max_steps': 100000, 'accumulate_grad_batches': 1, 'seed': 27, 'checkpoint_name': 'micro_albertino'}, 'inference_fix': False, 'nested': False, 'attn_impl': 'flash'}
2025-07-18 12:31:52,977 INFO    MsgRouterThr:38628 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
2025-07-18 12:31:54,874 ERROR   MainThread:38628 [redirect.py:_on_write():664] [no run ID] error in stdout callback
Traceback (most recent call last):
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/redirect.py", line 662, in _on_write
    cb(written_data)
    ~~^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 2487, in <lambda>
    lambda data: self._console_raw_callback("stdout", data),
                 ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 464, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 1632, in _console_raw_callback
    self._backend.interface.publish_output_raw(name, data)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface.py", line 763, in publish_output_raw
    self._publish_output_raw(o)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py", line 38, in _publish_output_raw
    self._publish(rec)
    ~~~~~~~~~~~~~^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py", line 39, in _publish
    self._sock_client.send_record_publish(record)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 174, in send_record_publish
    self.send_server_request(server_req)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
    ~~~~~~~~~~~~~~~~~~^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
2025-07-18 12:31:54,880 ERROR   MainThread:38628 [redirect.py:_on_write():664] [no run ID] error in stdout callback
Traceback (most recent call last):
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/redirect.py", line 662, in _on_write
    cb(written_data)
    ~~^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 2487, in <lambda>
    lambda data: self._console_raw_callback("stdout", data),
                 ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 464, in wrapper_fn
    return func(self, *args, **kwargs)
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/wandb_run.py", line 1632, in _console_raw_callback
    self._backend.interface.publish_output_raw(name, data)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface.py", line 763, in publish_output_raw
    self._publish_output_raw(o)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface_shared.py", line 38, in _publish_output_raw
    self._publish(rec)
    ~~~~~~~~~~~~~^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/interface/interface_sock.py", line 39, in _publish
    self._sock_client.send_record_publish(record)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 174, in send_record_publish
    self.send_server_request(server_req)
    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 154, in send_server_request
    self._send_message(msg)
    ~~~~~~~~~~~~~~~~~~^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 151, in _send_message
    self._sendall_with_error_handle(header + data)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/home/matteo/envs/torch-cuda/lib/python3.13/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
