{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a43c4f-edc6-464e-b874-c5bd03821f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from matformer.tokenizers import ByteLevelTokenizer\n",
    "from matformer.model_config import ModelConfig  \n",
    "from matformer.models import EntropyModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77eed7a5-a2f7-4402-9228-6190d722b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_plot(entropy,text):\n",
    "    plt.figure(figsize(10,5))\n",
    "    plt.plot(entropy.cpu(), marker='o', markersize=4, linestyle='-', linewidth=1)\n",
    "    plt.xticks(pos,text,rotation=45)\n",
    "    plt.xlabel('Chars')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.title('Entropy per char')\n",
    "    plt.grid(True,alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e3de21-eace-4591-8c38-72542776baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/matteo/Ricerca/miei_progetti/matformer/checkpoints/final_model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417dae64-6c8b-4432-8ca6-4c3afd2dff03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found this config:\n",
      "ModelConfig(name='Entropy Model', hidden_dim=768, ffn_factor=1.0, n_layers=14, n_heads=12, vocab_size=261, rms_norm_eps=1e-06, tie_word_embeddings=False, bias=False, attention_type='causal', sliding_window=512, sliding_window_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], max_seqlen=512, pad_id=260, bos_id=0, eos_id=1, device='cuda')\n",
      "Model loaded. Config = ModelConfig(name='Entropy Model', hidden_dim=768, ffn_factor=1.0, n_layers=14, n_heads=12, vocab_size=261, rms_norm_eps=1e-06, tie_word_embeddings=False, bias=False, attention_type='causal', sliding_window=512, sliding_window_layers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], max_seqlen=512, pad_id=260, bos_id=0, eos_id=1, device='cuda')\n"
     ]
    }
   ],
   "source": [
    "model,config = EntropyModel.load_from_checkpoint(checkpoint_path)\n",
    "print(f\"Model loaded. Config = {config}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f219470e-a3e0-4c20-ba9d-9e80a3bcc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Questa è una prova del modelo di Entropia. Dove otterremo i valori più alti?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d866843-9f44-4691-9589-03f5a8c3a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/Ricerca/miei_progetti/matformer/matformer/models.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prompt_ids=torch.tensor(tokenizer.encode(prompt).unsqueeze(0), device=self.device)\n"
     ]
    }
   ],
   "source": [
    "entropy=model.compute_entropy(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974261da-11a0-4f91-ab15-3b0f564dcd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff99695-27bb-415d-82c6-bbef91b889b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0098, 3.4239, 2.7130, 1.5943, 2.5390, 1.6038, 0.8123, 3.3343,\n",
       "        0.3727, 0.1142, 2.6291, 0.2743, 0.8908, 0.0268, 3.2349, 1.7160, 1.3267,\n",
       "        2.4646, 0.4101, 0.5155, 2.6182, 1.0659, 1.6027, 0.6472, 3.1469, 1.4523,\n",
       "        1.2010, 1.6515, 1.0290, 0.3533, 0.9529, 3.7451, 1.2867, 1.0460, 3.4480,\n",
       "        3.1791, 2.2135, 0.2823, 0.7518, 1.3559, 0.8873, 1.9974, 1.4975, 1.3895,\n",
       "        3.0159, 1.5702, 0.8751, 0.7013, 0.9116, 2.4679, 2.0501, 0.0049, 0.3913,\n",
       "        0.6011, 1.9569, 1.4151, 0.8309, 0.2745, 0.3936, 2.7269, 1.0357, 2.6209,\n",
       "        1.3755, 1.0071, 0.4286, 0.0400, 0.0576, 0.2919, 2.5552, 1.3976, 1.2454,\n",
       "        0.0578, 0.1638, 2.8981, 2.3518, 0.7211, 1.6147, 1.3230, 0.7103],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
