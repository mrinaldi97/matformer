{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd488bf1-0629-4e0e-b4a7-2a6d2a4e3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from matformer.tensors_dataclasses import TensorDC, NormalTensor, PaddedTensor, UnpaddedTensor\n",
    "import torch\n",
    "from matformer.matformer_registry import registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7504811e-3446-45e1-9860-ad33fa12814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensioni ipotetiche\n",
    "q_dim=512\n",
    "k_dim=512\n",
    "v_dim=512\n",
    "seqlen=1024\n",
    "batch_size=32\n",
    "n_heads=8\n",
    "bias=False\n",
    "assert q_dim%n_heads==0\n",
    "head_size=q_dim//n_heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651675e8-31c4-4f46-81d4-aea2fe778b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensori di prova\n",
    "#query_input_batched=torch.randn(batch_size,seqlen,q_dim)\n",
    "query_input_unbatched=torch.randn(batch_size*seqlen,q_dim)\n",
    "#print(f\"Batched: {query_input_batched.shape}, Unbatched: {query_input_unbatched.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1533b05b-6ae4-4d83-8665-92d37cedf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proiezioni iniziali (a q_dim o 3*q_dim)\n",
    "#if not is_cross_attention or self.qkv_samedim:\n",
    "#self.packed_proj = nn.Linear(self.q_dim, 3 * q_dim, bias=bias)\n",
    "packed_proj=registry.create('linear','linear',in_features=q_dim, out_features=3*q_dim,bias=bias)\n",
    "#else:\n",
    "q_proj=registry.create('linear','linear',in_features=q_dim, out_features=q_dim,bias=bias)\n",
    "#k_proj=registry.create('linear','linear',in_features=k_dim, out_features=q_dim,bias=bias)\n",
    "#v_proj=registry.create('linear','linear',in_features=v_dim, out_features=q_dim,bias=bias)\n",
    "#self.q_proj = nn.Linear(q_dim, q_dim, bias=bias)\n",
    "#self.k_proj = nn.Linear(k_dim, q_dim, bias=bias)\n",
    "#self.v_proj = nn.Linear(v_dim, q_dim, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ce549f-216f-4cb3-baac-b9d1956ba205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qkv_projected_batched=NormalTensor(tensor=packed_proj(query_input_batched),tensor_order='?S(3*D)')\n",
    "qkv_projected=NormalTensor(tensor=packed_proj(query_input_unbatched),tensor_order='?S(3*D)')\n",
    "#print(f\"(QKV PACKED PROJECTION): Batched: {qkv_projected_batched.shape}, Unbatched: {qkv_projected_unbatched.shape}\")\n",
    "#qkv_projected_shape='?S(3*D)'\n",
    "\n",
    "q=NormalTensor(tensor=q_proj(query_input_unbatched),tensor_order='?SD')\n",
    "#q_unbatched=q_proj(query_input_unbatched)\n",
    "#print(f\"(Q NORMAL PROJECTION): Batched: {q_batched.shape}, Unbatched: {q_unbatched.shape}\")\n",
    "#q_projected_shape='?SD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301f6d94-b43f-4bcc-bf4c-b50eb215c2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?SD'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.tensor_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36b53554-d665-454e-863c-a11765fea919",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_projected_heads=NormalTensor(tensor=qkv_projected.tensor.unflatten(-1,[3,n_heads,head_size]),tensor_order='?S3HD')\n",
    "#qkv_projected_heads_unbatched=qkv_projected_unbatched.unflatten(-1,[3,n_heads,head_size])\n",
    "q_projected_heads=NormalTensor(tensor=q.tensor.unflatten(-1,[n_heads,head_size]),tensor_order='?SHD')\n",
    "#q_projected_heads_unbatched=q_unbatched.unflatten(-1,[n_heads,head_size])\n",
    "#print(f\"Packed: batched: {qkv_projected_heads_batched.shape} unbatched: {qkv_projected_heads_unbatched.shape}\")\n",
    "#print(f\"Normal: batched: {q_projected_heads_batched.shape} unbatched: {q_projected_heads_unbatched.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bf364a9-f9e8-44ea-96da-32d12a912a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "def _pack_qkv(q, k, v):\n",
    "    assert q.tensor_order == k.tensor_order == v.tensor_order, \"QKV must have same tensor order\"\n",
    "    normalize = lambda s: s.translate(str.maketrans('', '', '?B'))\n",
    "    current_order_norm = normalize(q.tensor_order)\n",
    "    \n",
    "    if current_order_norm == \"HSD\":\n",
    "        # [?, H, S, D] => [?, S, H, D]\n",
    "        q_t = q.tensor.transpose(1, 2)\n",
    "        k_t = k.tensor.transpose(1, 2)\n",
    "        v_t = v.tensor.transpose(1, 2)\n",
    "        #  [?, S, 3, H, D]\n",
    "        packed_tensor = torch.stack([q_t, k_t, v_t], dim=2)\n",
    "        new_order = '?S3HD'\n",
    "    elif current_order_norm == \"SHD\":\n",
    "        # [?, S, 3, H, D]\n",
    "        packed_tensor = torch.stack([q.tensor, k.tensor, v.tensor], dim=2)\n",
    "        new_order = '?S3HD'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported tensor order: {q.tensor_order}\")\n",
    "    \n",
    "    return replace(q, tensor=packed_tensor, tensor_order=new_order)\n",
    "\n",
    "def _unpack_qkv(qkv_packed):\n",
    "        # S3HD => ?SHD\n",
    "        q_t, k_t, v_t = qkv_packed.tensor.unbind(dim=1)\n",
    "        order = qkv_packed.tensor_order.replace('3', '')\n",
    "        return (replace(qkv_packed, tensor=q_t, tensor_order=order),\n",
    "                replace(qkv_packed, tensor=k_t, tensor_order=order),\n",
    "                replace(qkv_packed, tensor=v_t, tensor_order=order))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f864aa6-e7a7-41a4-897b-306d81936cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 8, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_projected_heads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2511b0e7-b6d8-4868-9cd7-c9957fc9d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_repacked=_pack_qkv(q,q,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba5f0886-a391-49dd-b4cd-e5e7720e4232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?SD'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.tensor_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8083cd79-a909-4381-bdfb-df24419df621",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=_unpack_qkv(qkv_projected_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "183b5005-14ed-4504-bd39-09f22be2cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=_pack_qkv(q_projected_heads,q_projected_heads,q_projected_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef6a0695-cf10-40b9-89bb-054ecbe57a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?S3HD'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.tensor_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450507e-de6a-4463-aebe-5839220a2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6843b3dc-021e-4faf-accb-b189fb8f703a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?S3HD'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_projected_heads.tensor_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7910474-e916-41b7-bd5a-3adcf943a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transpose_for_kernel(a,b,identifier):\n",
    "    print(f\"Originale: {identifier}\")\n",
    "    identifier=list(identifier)\n",
    "    c=identifier[a]\n",
    "    identifier[a]=identifier[b]\n",
    "    identifier[b]=c\n",
    "    return \"\".join(identifier)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593a797-95ba-46b5-8a7b-755e26cd4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose(1,2,q_heads_shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44de53f6-c8d2-4fea-9c22-46f52858191c",
   "metadata": {},
   "source": [
    "ORIGINALE HO:\n",
    "    BSHD\n",
    "    BS3HD\n",
    "SDPDA VUOLE:\n",
    "        'tensor_order_input': 'BHSD',\n",
    "FLASH VUOLE:\n",
    "        'tensor_order_input': 'BSHD',\n",
    "        'tensor_order_qkv_packed_input': 'BS3HD',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fa773-b331-4eb8-8e95-f2f3ead0f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_projected_heads_batched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae7c43-e8cf-4ae8-aebe-280a4ada9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova=q_projected_heads_batched.transpose(1,2)\n",
    "q_projected_heads_batched.shape\n",
    "prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72611377-d355-4888-a398-637ef27ed4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heads creation\n",
    "            t = qkv_projected.tensor.unflatten(-1, [3, self.nheads, self.head_dim])\n",
    "            # Detect whether batch dim exists (padded / normal) or not (unpadded represented as (S, 3, H, Hd))\n",
    "            if t.dim() == 5:\n",
    "                order = 'S3HD'\n",
    "            elif t.dim() == 4:\n",
    "                order = 'S3HD'\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported packed qkv tensor shape: {tuple(t.shape)}\")\n",
    "            qkv_projected = NormalTensor(tensor=t, extra_attributes={'tensor_order': order})\n",
    "        else:\n",
    "            q = NormalTensor(tensor=q.tensor.unflatten(-1, [self.nheads, self.head_dim]).transpose(1, 2), extra_attributes={'tensor_order': 'HSD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da743f65-95b4-478b-a77e-7cd274f52912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHD'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'?SHD'.replace('?','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2eeea2-498f-4bd5-8b92-8893f0f69187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHD'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'BSHD'.replace('B','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e406c9-34b3-4807-971d-cc218b90710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SHD'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='BSHD'\n",
    "a.replace('B','').replace('?','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfa97be9-baba-45b2-beb4-8c4eb2ccf9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 8, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_projected_heads_batched.shape #?SHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ac8ec-b022-4535-97a2-4ba42c761f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03be3220-51ea-467f-8d05-cefe8b49fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come ripaccare le tre rappresentazioni separate?\n",
    "repacked=torch.cat([q_projected_heads_batched, q_projected_heads_batched, q_projected_heads_batched], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "941ec1f3-b4d4-43be-b848-8db43576443d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 24, 64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repacked.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
