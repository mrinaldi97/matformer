{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f84a7f-1394-414d-8841-297d85872b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "986391b6-a33b-43fa-be1a-b02489a638f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 10])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_capacity=4\n",
    "indexes=torch.tensor([[0,1,6],[1,2,0]]).unsqueeze(0)\n",
    "router_probs = torch.zeros(1, 2, 10)\n",
    "router_probs[0, 0, [0,1,6]] = torch.tensor([0.7, 0.6, 0.2])\n",
    "router_probs[0, 1, [1,2,0]] = torch.tensor([0.8, 0.5, 0.3])\n",
    "exp_mask = F.one_hot(indexes, num_classes=10)  # [B, T, k, n_exp]\n",
    "exp_mask = exp_mask.view(indexes.size(0)*indexes.size(1), 3, 10)  # [B * T, k, n_exp]\n",
    "exp_mask = exp_mask.permute(1, 0, 2)  # [k, B * T, n_exp] #This permutation is done to order the expert selected for their importance (rank) for each token\n",
    "# For each token contains the indexes of the top-k experts in one hot encoding\n",
    "# For example, exp_mask[0] contains the \"best\" expert selected for each token, while exp_mask[K] the less important expert. This ordering is important to prioritize experts later\n",
    "exp_rank = exp_mask.reshape(3 * indexes.size(0)*indexes.size(1), 10)  # [k * B * T, n_exp]\n",
    "exp_rank = torch.cumsum(exp_rank, dim=0) - 1  # [k * B * T, n_exp]\n",
    "exp_rank = exp_rank.reshape(3,  indexes.size(0)*indexes.size(1), 10)  # [k, B * T, n_exp]\n",
    "exp_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "193c7d9a-43ef-4029-930b-99cef72d8618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask *= torch.lt(exp_rank, exp_capacity) # [k, B * T, n_exp]\n",
    "used_capacity = torch.sum(exp_mask, dim=(0, 1)) # [n_exp]\n",
    "exp_rank = torch.sum(exp_mask * exp_rank, dim=-1) # [k, B * T]\n",
    "exp_rank\n",
    "router_probs = router_probs.view(indexes.size(0)*indexes.size(1),10)[None, :] # [1, B * T, n_exp]\n",
    "exp_weights = exp_mask * router_probs # [k, B * T, n_exp]\n",
    "exp_rank_sc = F.one_hot(exp_rank, num_classes=exp_capacity) # [k, B * T, exp_capacity]\n",
    "exp_rank_sc\n",
    "cb_weight = torch.sum(exp_weights.unsqueeze(3) * exp_rank_sc.unsqueeze(2), dim=0)\n",
    "sec_mask = cb_weight.bool() # binary mask of selected experts for each token\n",
    "#used_capacity\n",
    "exp_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "170afd78-036f-4f6a-a720-3baaa9b76d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_mask.permute(1,2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41e23547-d56a-462a-aa5c-1a8d9a927f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b414f91-6bde-46d2-a848-aa8dc620c9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -1, -1, -1, -1,  0, -1, -1, -1, -1],\n",
       "        [ 0, -1, -1, -1, -1,  0, -1, -1, -1, -1],\n",
       "        [ 0, -1, -1, -1,  0,  0, -1, -1, -1, -1],\n",
       "        [ 0, -1, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "        [ 0,  0, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "        [ 0,  1, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "        [ 0,  1, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  2, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  3, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  4, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  4, -1,  0,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  4,  0,  0,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  4,  1,  0,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  4,  1,  1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  5,  1,  1,  0,  0,  0, -1,  0, -1],\n",
       "        [ 0,  5,  1,  1,  0,  0,  0,  0,  0, -1],\n",
       "        [ 0,  5,  1,  1,  0,  0,  0,  0,  1, -1],\n",
       "        [ 0,  5,  2,  1,  0,  0,  0,  0,  1, -1],\n",
       "        [ 0,  5,  2,  1,  0,  0,  1,  0,  1, -1],\n",
       "        [ 0,  5,  2,  1,  0,  0,  1,  0,  1,  0],\n",
       "        [ 0,  5,  2,  2,  0,  0,  1,  0,  1,  0],\n",
       "        [ 0,  5,  2,  2,  1,  0,  1,  0,  1,  0],\n",
       "        [ 0,  5,  2,  2,  1,  0,  1,  1,  1,  0],\n",
       "        [ 0,  5,  2,  2,  1,  0,  1,  1,  1,  1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d2d7b79-a566-4571-ba5d-63ac415f2097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a210f3a6-584b-4d9c-aece-2471fe7fd038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1, -1, -1, -1, -1,  0, -1, -1, -1, -1],\n",
       "         [ 0, -1, -1, -1, -1,  0, -1, -1, -1, -1],\n",
       "         [ 0, -1, -1, -1,  0,  0, -1, -1, -1, -1],\n",
       "         [ 0, -1, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "         [ 0,  0, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "         [ 0,  1, -1, -1,  0,  0,  0, -1, -1, -1],\n",
       "         [ 0,  1, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  2, -1, -1,  0,  0,  0, -1,  0, -1]],\n",
       "\n",
       "        [[ 0,  3, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  4, -1, -1,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  4, -1,  0,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  4,  0,  0,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  4,  1,  0,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  4,  1,  1,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  5,  1,  1,  0,  0,  0, -1,  0, -1],\n",
       "         [ 0,  5,  1,  1,  0,  0,  0,  0,  0, -1]],\n",
       "\n",
       "        [[ 0,  5,  1,  1,  0,  0,  0,  0,  1, -1],\n",
       "         [ 0,  5,  2,  1,  0,  0,  0,  0,  1, -1],\n",
       "         [ 0,  5,  2,  1,  0,  0,  1,  0,  1, -1],\n",
       "         [ 0,  5,  2,  1,  0,  0,  1,  0,  1,  0],\n",
       "         [ 0,  5,  2,  2,  0,  0,  1,  0,  1,  0],\n",
       "         [ 0,  5,  2,  2,  1,  0,  1,  0,  1,  0],\n",
       "         [ 0,  5,  2,  2,  1,  0,  1,  1,  1,  0],\n",
       "         [ 0,  5,  2,  2,  1,  0,  1,  1,  1,  1]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81e246e5-f966-4d3e-860d-b0e37e317159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=F.one_hot(torch.Tensor(a).to(torch.long),num_classes=10)\n",
    "b=b.view(8,3,10)\n",
    "b=b.permute(1,0,2) #k,b*t,exp\n",
    "c=b.reshape(3*8,10)\n",
    "c=torch.cumsum(c,dim=0)-1\n",
    "c=c.reshape(3,8,10)\n",
    "c.shape\n",
    "b*=torch.lt(c,2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad68044-2f4e-4579-acbb-966a62ffb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_rank = exp_mask.reshape(self.top_k * num_tokens, self.n_exp)  # [k * B * T, n_exp]\n",
    "exp_rank = torch.cumsum(exp_rank, dim=0) - 1  # cumulative sum of expert selections [k * B * T, n_exp]\n",
    "exp_rank = exp_rank.reshape(self.top_k, num_tokens, self.n_exp)  # [k, B * T, n_exp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa730f7-6b2e-4c60-beed-f96ab21d3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(nn.Module):\n",
    "    def __init__(self,hidden_size,n_experts):\n",
    "        self.linear_projection=nn.Linear(hidden_size,n_experts)\n",
    "    def forward(x):\n",
    "        \n",
    "        ctx = nullcontext() if not self.router_use_full_prec else torch.amp.autocast(device_type=self.device, enabled=False)\n",
    "        with ctx: # It's better to force the router to run in fp32 to avoid round errors from exponential\n",
    "            logits=self.linear_projection(x)\n",
    "            top_k_logits, top_k_indices = logits.topk(self.top_k, dim=-1) # B,S,K\n",
    "            # Executing the softmax only on the top_k logits, masking the rest\n",
    "            router_probs=torch.full_like(logits,float('-inf')) #B,S,N_E\n",
    "            router_probs.scatter_(-1,top_k_indices,top_k_logits)\n",
    "            router_probs=F.softmax(router_probs,dim=-1)\n",
    "            \"\"\"\n",
    "            Experts' capacity is computed according to the formula:\n",
    "            capacity=(K*B*S/N)*cap_factor\n",
    "            where:\n",
    "                K = Active experts\n",
    "                B = Batch size\n",
    "                S = Sequence length\n",
    "                N = Total number of expers\n",
    "                cap_factor = capacity factor (ex. 1.25 for training, 2 for inference)\n",
    "            \"\"\"            \n",
    "            expert_capacity=math.floor(k*cap_factor*num_tokens)/num_exp\n",
    "            expert_capacity+=capacity%2 # Capacity must be even\n",
    "            expert_capacity=int(expert_capacity)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b7a3506-39a4-47f0-b722-64b527d091e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_capacity(num_tokens):\n",
    "    \"\"\"\n",
    "    An helper function to compute experts' capacity according to the formula:\n",
    "    capacity=(K*B*S/N)*cap_factor\n",
    "    where:\n",
    "        K = Active experts\n",
    "        B = Batch size\n",
    "        S = Sequence length\n",
    "        N = Total number of expers\n",
    "        cap_factor = capacity factor (ex. 1.25 for training, 2 for inference)\n",
    "    \"\"\"\n",
    "    cap_factor=1.25\n",
    "    k=1\n",
    "    num_exp=8\n",
    "    capacity=math.floor(k*cap_factor*num_tokens)/num_exp\n",
    "    \"\"\"\n",
    "        capacity_factor = self.train_capacity if self.training else self.eval_capacity\n",
    "        capacity = math.floor(self.top_k * capacity_factor * tokens_per_batch / self.n_exp)\n",
    "        capacity += capacity % 2 # make sure capacity is an even number\n",
    "        capacity = max(capacity, self.min_capacity) # use min capacity\n",
    "        assert capacity > 0\n",
    "        return int(capacity)    \n",
    "    \"\"\"\n",
    "    return capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd13aa2-33ac-462c-bc41-fe7b829a71f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(1*1.25*1024/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efb3994b-108d-49b8-bca8-55f987616522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
