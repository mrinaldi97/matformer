{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd488bf1-0629-4e0e-b4a7-2a6d2a4e3143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from matformer.tensors_dataclasses import TensorDC, NormalTensor, PaddedTensor, UnpaddedTensor\n",
    "import torch\n",
    "from matformer.matformer_registry import registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7504811e-3446-45e1-9860-ad33fa12814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensioni ipotetiche\n",
    "q_dim=512\n",
    "k_dim=512\n",
    "v_dim=512\n",
    "seqlen=1024\n",
    "batch_size=32\n",
    "n_heads=8\n",
    "bias=False\n",
    "assert q_dim%n_heads==0\n",
    "head_size=q_dim//n_heads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "651675e8-31c4-4f46-81d4-aea2fe778b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched: torch.Size([32, 1024, 512]), Unbatched: torch.Size([32768, 512])\n"
     ]
    }
   ],
   "source": [
    "# Tensori di prova\n",
    "query_input_batched=torch.randn(batch_size,seqlen,q_dim)\n",
    "query_input_unbatched=torch.randn(batch_size*seqlen,q_dim)\n",
    "print(f\"Batched: {query_input_batched.shape}, Unbatched: {query_input_unbatched.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1533b05b-6ae4-4d83-8665-92d37cedf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proiezioni iniziali (a q_dim o 3*q_dim)\n",
    "#if not is_cross_attention or self.qkv_samedim:\n",
    "#self.packed_proj = nn.Linear(self.q_dim, 3 * q_dim, bias=bias)\n",
    "packed_proj=registry.create('linear','linear',in_features=q_dim, out_features=3*q_dim,bias=bias)\n",
    "#else:\n",
    "q_proj=registry.create('linear','linear',in_features=q_dim, out_features=q_dim,bias=bias)\n",
    "k_proj=registry.create('linear','linear',in_features=k_dim, out_features=q_dim,bias=bias)\n",
    "v_proj=registry.create('linear','linear',in_features=v_dim, out_features=q_dim,bias=bias)\n",
    "#self.q_proj = nn.Linear(q_dim, q_dim, bias=bias)\n",
    "#self.k_proj = nn.Linear(k_dim, q_dim, bias=bias)\n",
    "#self.v_proj = nn.Linear(v_dim, q_dim, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05ce549f-216f-4cb3-baac-b9d1956ba205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(QKV PACKED PROJECTION): Batched: torch.Size([32, 1024, 1536]), Unbatched: torch.Size([32768, 1536])\n",
      "(Q NORMAL PROJECTION): Batched: torch.Size([32, 1024, 512]), Unbatched: torch.Size([32768, 512])\n"
     ]
    }
   ],
   "source": [
    "qkv_projected_batched=packed_proj(query_input_batched)\n",
    "qkv_projected_unbatched=packed_proj(query_input_unbatched)\n",
    "print(f\"(QKV PACKED PROJECTION): Batched: {qkv_projected_batched.shape}, Unbatched: {qkv_projected_unbatched.shape}\")\n",
    "qkv_projected_shape='?S(3*D)'\n",
    "\n",
    "q_batched=q_proj(query_input_batched)\n",
    "q_unbatched=q_proj(query_input_unbatched)\n",
    "print(f\"(Q NORMAL PROJECTION): Batched: {q_batched.shape}, Unbatched: {q_unbatched.shape}\")\n",
    "q_projected_shape='?SD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36b53554-d665-454e-863c-a11765fea919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packed: batched: torch.Size([32, 1024, 3, 8, 64]) unbatched: torch.Size([32768, 3, 8, 64])\n",
      "Normal: batched: torch.Size([32, 1024, 8, 64]) unbatched: torch.Size([32768, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "qkv_projected_heads_batched=qkv_projected_batched.unflatten(-1,[3,n_heads,head_size])\n",
    "qkv_projected_heads_unbatched=qkv_projected_unbatched.unflatten(-1,[3,n_heads,head_size])\n",
    "q_projected_heads_batched=q_batched.unflatten(-1,[n_heads,head_size])\n",
    "q_projected_heads_unbatched=q_unbatched.unflatten(-1,[n_heads,head_size])\n",
    "print(f\"Packed: batched: {qkv_projected_heads_batched.shape} unbatched: {qkv_projected_heads_unbatched.shape}\")\n",
    "print(f\"Normal: batched: {q_projected_heads_batched.shape} unbatched: {q_projected_heads_unbatched.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bf364a9-f9e8-44ea-96da-32d12a912a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.84375"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_heads_shape='?S3HD'\n",
    "q_heads_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "562fa773-b331-4eb8-8e95-f2f3ead0f525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 3, 8, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv_projected_heads_batched.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72611377-d355-4888-a398-637ef27ed4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heads creation\n",
    "            t = qkv_projected.tensor.unflatten(-1, [3, self.nheads, self.head_dim])\n",
    "            # Detect whether batch dim exists (padded / normal) or not (unpadded represented as (S, 3, H, Hd))\n",
    "            if t.dim() == 5:\n",
    "                order = 'S3HD'\n",
    "            elif t.dim() == 4:\n",
    "                order = 'S3HD'\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Unsupported packed qkv tensor shape: {tuple(t.shape)}\")\n",
    "            qkv_projected = NormalTensor(tensor=t, extra_attributes={'tensor_order': order})\n",
    "        else:\n",
    "            q = NormalTensor(tensor=q.tensor.unflatten(-1, [self.nheads, self.head_dim]).transpose(1, 2), extra_attributes={'tensor_order': 'HSD'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
