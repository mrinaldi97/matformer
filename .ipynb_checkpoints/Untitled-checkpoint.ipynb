{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e134ab-1f4b-4594-b16c-52979b35b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matformer.matformer_dataset import MatformerDataset\n",
    "from inference import load_inference_model\n",
    "from matformer.transformer_blocks import EntropyModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127c2a73-f5c6-465b-a386-7d5c070d2976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found this config:\n",
      "ModelConfig(hidden_size=512, ffn_factor=1.0, num_hidden_layers=10, num_attention_heads=8, vocab_size=260, pad_token_id=258, bos_token_id=256, eos_token_id=257, tie_word_embeddings=False, rms_norm_eps=1e-06, attention_type=[], sliding_window_size=512, sliding_layers=[], sliding_type='disabled', max_position_embeddings=1023, block_size_for_attention=128, compile_flexattn=False, bias=False, name='EntropySmall', training_objective='autoregressive', is_causal=True, alibi=True, attn_impl='flash', has_text_autoencoder=None, has_entropy_model=None)\n"
     ]
    }
   ],
   "source": [
    "model,cfg=load_inference_model('checkpoints/entropy_liber_wiki_1024_adam.ckpt',EntropyModel,torch.device('cuda'),'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8d174e-aa4a-493f-8b49-691ce35cdc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: ENTROPY MODE ENABLED\n",
      "Length will not be returned\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MatformerDataset' object has no attribute 'chunk_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mMatformerDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m   \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../matformer_norepo/Minerva1024_lmdb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m   \u001b[49m\u001b[43mmodality\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mentropy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m   \u001b[49m\u001b[43mn_bytes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m   \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m   \u001b[49m\u001b[43mentropy_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m   \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'ids' or 'dict'\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ricerca/miei_progetti/matformer/matformer/matformer_dataset.py:632\u001b[39m, in \u001b[36mMatformerDataset.__init__\u001b[39m\u001b[34m(self, path, modality, chunk_size, tokens, n_bytes, state, byte_tokenizer, entropy_model, entropy_smoothing, return_type)\u001b[39m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m.len = \u001b[38;5;28mself\u001b[39m.precomputed_byte_lengths[\u001b[32m0\u001b[39m]\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWARNING: length for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size\u001b[49m*\u001b[38;5;28mself\u001b[39m.token_per_segment\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m was not computed during dataset creation!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    633\u001b[39m     \u001b[38;5;28mself\u001b[39m.len=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[38;5;28mself\u001b[39m._load_next_document()\n",
      "\u001b[31mAttributeError\u001b[39m: 'MatformerDataset' object has no attribute 'chunk_size'"
     ]
    }
   ],
   "source": [
    "ds = MatformerDataset(\n",
    "   path=\"../matformer_norepo/Minerva1024_lmdb\",  \n",
    "   modality='entropy',\n",
    "   n_bytes=512, \n",
    "   chunk_size=10,  \n",
    "   entropy_model=model, \n",
    "   entropy_smoothing=2,\n",
    "   return_type='text'  # or 'ids' or 'dict'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
