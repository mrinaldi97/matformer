{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c499aaae-f81b-491c-bf09-3051e4c86cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esperimento 1: Si riesce a fare un'attention se query e KV hanno seqlen diverse? SI FUNZIONA BENISSIMO!\n",
    "import torch\n",
    "from matformer.transformer_functions import MultiHeadAttention\n",
    "from matformer.tensors_dataclasses import TensorDC, NormalTensor, PaddedTensor, UnpaddedTensor\n",
    "q_dim=768\n",
    "k_dim=768\n",
    "v_dim=768\n",
    "hidden_size=768\n",
    "nheads=12\n",
    "bias=False\n",
    "block_mask=None\n",
    "attn_impl='sdpa'\n",
    "alibi=False\n",
    "is_causal=False\n",
    "device='cpu'\n",
    "batch=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429bb12-13a0-44d0-b5ca-ac1f7d78d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query input (seqlen=1) (B,S,D)\n",
    "query_input=NormalTensor(tensor=torch.randn(batch,1,q_dim))\n",
    "# Key,Value input (seqlen=27) (B,S,D)\n",
    "key_input=NormalTensor(tensor=torch.randn(batch,27,k_dim))\n",
    "value_input=key_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588ceaf-42a3-4181-a39d-ab7c51ff7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn=MultiHeadAttention(q_dim=q_dim,k_dim=k_dim,v_dim=v_dim,hidden_size=hidden_size,nheads=nheads,bias=bias,block_mask=block_mask,attn_impl=attn_impl,alibi=alibi,is_causal=is_causal,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7edd6-a28f-419e-8133-6c72aba88ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn(query_input=query_input,key_input=key_input,value_input=value_input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd8b8e-5bde-48da-a50e-f3168ee2bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esperimento2: studiare il dataloader\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39002cac-a78c-4232-8ad5-581e7d86cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_a_caso(max_len=27,PAD_TOKEN=-1,batch_size=16, device=None):\n",
    "    lengths = torch.randint(1, max_len + 1, (batch_size,))\n",
    "    tensors=torch.stack([torch.cat([torch.randint(0, 256, (i,)), torch.ones(max_len-i)*PAD_TOKEN]) for i in lengths]).int()\n",
    "    padding_mask=tensors==PAD_TOKEN\n",
    "    return PaddedTensor(tensor=tensors,padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8774c360-e4dd-4c90-8522-9911b3a033e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PaddedTensor(tensor=tensor([[ 82,  44,  20, 169, 247, 105,  34,  44, 195,   8,  33,  35, 120, 132,\n",
       "         214,  62, 208, 227, 129, 232, 119, 199,  34,  -1,  -1,  -1,  -1],\n",
       "        [  1,   2, 163,  35,  70, 226,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [253, 253, 109, 162,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 76, 204,  48, 125, 215,  19, 217, 220,  75, 205,   0, 211, 169, 176,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 80, 123,  97, 154,  56,  85,   8, 134, 216, 118,  52, 118, 233,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [255,  29,  63,  35, 113, 228,   0, 242, 194, 239, 150, 195, 104, 197,\n",
       "          56,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [223, 229,  65, 183,  64, 192,  41,  29, 237,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [119,  67,  54,  61, 104, 178,  32, 202, 196,  56, 111, 135, 202, 143,\n",
       "         167,  59,  37, 183, 128, 127,  63,  99, 211,  22,   6,  82, 244],\n",
       "        [114, 128, 144,  27, 124, 233, 157,  91, 138,  33, 154, 229,  60,  62,\n",
       "           1,  85,  22,  73, 106, 109, 201,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [245,  48, 101, 250,  22,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 53,  56,  21,  55,  19, 103, 115, 233, 220, 207, 202, 173, 220, 217,\n",
       "          67, 143, 245,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [ 92,  14, 230, 177,  75, 111, 185,  25, 153,  42,  84,  10, 252,  58,\n",
       "         107, 202, 115, 133, 108, 116,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [153, 210,  84, 132, 235,  94,  12, 140,  94,  32, 183,  94, 117, 198,\n",
       "         250,  47, 122,  37, 103,  92, 243, 200,  90,  -1,  -1,  -1,  -1],\n",
       "        [107, 238, 209, 182,  89,  65, 233,  40, 105, 100, 175,  62, 124,  92,\n",
       "          36,  28,  37, 220,  84,  63,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [177, 107,  71,  30,  91, 165, 202,  14, 111, 104, 117,  11, 160,  39,\n",
       "         196, 241, 117,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1],\n",
       "        [104,  35, 131, 137, 139, 136, 124,  35,  70, 122, 254, 173, 247, 104,\n",
       "         131,  57,  15, 187, 235,  71, 111,  52, 116, 236, 253,  -1,  -1]],\n",
       "       dtype=torch.int32), cloze_mask=None, document_mask=None, padding_mask=tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True,  True]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8106c1e-bca0-48dd-af02-db0750766da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "unpadded_lengths=UnpaddedTensor(\n",
    "    tensor=lengths,\n",
    "    indices=indices,\n",
    "    cu_seqlens=torch.arange(batch_size+1),\n",
    "    max_seq_len=1,\n",
    "    original_seq_len=1,\n",
    "    batch_size=lengths.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe3a9bc-0b14-49d0-a1a0-d31f0e7fa661",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadded_input_ids.pad().tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6c93b-be83-4135-9a8d-6c66b26deabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_len=25\n",
    "indices=torch.tensor([],dtype=torch.int)\n",
    "for l in lengths:\n",
    "    differenza=max_len-l\n",
    "    tensore=torch.cat([torch.ones(l),torch.zeros(differenza)])\n",
    "    indices=torch.cat([indices,tensore])\n",
    "indices=indices.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef5e50e7-c525-4c33-a378-15958de976fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_a_caso(max_len=27,PAD_TOKEN=-1,batch_size=16, device=None):\n",
    "    lengths = torch.randint(1, max_len + 1, (batch_size,))\n",
    "    tensors=torch.stack([torch.cat([torch.randint(0, 256, (i,)), torch.ones(max_len-i)*PAD_TOKEN]) for i in lengths]).int()\n",
    "    padding_mask=tensors==PAD_TOKEN\n",
    "    return PaddedTensor(tensor=tensors,padding_mask=padding_mask), NormalTensor(tensor=lengths)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226c692-1e86-4850-b8bc-d2b92871fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadded_input_ids=UnpaddedTensor(\n",
    "    tensor=input_ids,\n",
    "    indices=indices,\n",
    "    cu_seqlens=torch.cat([_zero,lengths.cumsum(0)]),\n",
    "    max_seq_len=25,\n",
    "    original_seq_len=25,\n",
    "    batch_size=batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239d6dd-13f7-4e5d-a235-a1ab0b5d465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpadded_input_ids.pad().tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "089c6181-f8c5-4c93-80e0-245456cf8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c56bf97c-6753-4b8e-82f2-ed160a4d1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "prova=nn.Embedding(258,512,padding_idx=257)\n",
    "prova2=nn.Embedding(30,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21fa3b38-b7c3-4fc2-849e-b96e950e340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=genera_a_caso(PAD_TOKEN=257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dce6f82d-1eb2-43b1-8bb0-36551235f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 27, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova(a.tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e96ce366-436b-4a3e-a0a2-6352b29ef7f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mA\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
