{
  "model_class": "TransformerWithCharAutoencoder",
  "name":"TextPatchGPT",
  "has_text_autoencoder": true,
  "model_config": {
    "name": "TextPatchGPT",
    "hidden_size": 768,
    "ffn_factor": 1.0,
    "num_hidden_layers": 10,
    "num_attention_heads": 12,
    "vocab_size": 260,
    "bos_token_id": 0,
    "eos_token_id": 0,
    "pad_token_id": 0,
    "tie_word_embeddings": false,
    "rms_norm_eps": 1e-6,
    "attention_type": [],
    "sliding_window_size": 512,
    "sliding_layers": [],
    "sliding_type": "disabled",
    "max_position_embeddings": 512,
    "block_size_for_attention": 128,
    "compile_flexattn": false,
    "bias": false,
    "training_objective": "autoregressive",
    "alibi": true,
    "is_causal": true,
    "attn_impl": "flash",
    "encoder": {
      "name": "TransChar-Enc-768-5L",
      "hidden_size":512,
      "ffn_factor": 1.0,
      "num_hidden_layers": 4,
      "num_attention_heads": 8,
      "vocab_size": 260,
      "bos_token_id": 257,
      "eos_token_id": 258,
      "pad_token_id": 259,
      "tie_word_embeddings": false,
      "rms_norm_eps": 1e-6,
      "attention_type": [],
      "sliding_window_size": 1024,
      "sliding_layers": [],
      "sliding_type": "disabled",
      "max_position_embeddings": 26,
      "block_size_for_attention": 128,
      "compile_flexattn": false,
      "bias": false,
      "training_objective": "encoder",
      "alibi": true,
      "is_causal": false,
      "attn_impl": "sdpa",
      "has_text_autoencoder": true
    },
    "decoder": {
      "name": "TransChar-Dec-768-3L",
      "hidden_size": 512,
      "ffn_factor": 1.0,
      "num_hidden_layers": 3,
      "num_attention_heads": 8,
      "vocab_size": 260,
      "bos_token_id": 257,
      "eos_token_id": 258,
      "pad_token_id": 259,
      "tie_word_embeddings": false,
      "rms_norm_eps": 1e-6,
      "attention_type": [],
      "sliding_window_size": 1024,
      "sliding_layers": [],
      "sliding_type": "disabled",
      "max_position_embeddings": 27,
      "block_size_for_attention": 128,
      "compile_flexattn": false,
      "bias": false,
      "training_objective": "decoder",
      "alibi": true,
      "is_causal": false,
      "attn_impl": "sdpa"
    },
    "entropy": {
      "entropy_model_path": "checkpoints/entropy_liber_wiki_1024_adam.ckpt",
      "entropy_smoothing": 2
    }
  },
  "training": {
    "optimizer": "adam",
    "lr_scheduling": true,
    "lr": 0.0002,
    "final_lr": 0.00001,
    "weight_decay": 0.01,
    "scheduler": "custom",
    "warmup_steps": 3500,
    "hold_steps": 3500,
    "max_epochs": 1,
    "accumulate_grad_batches": 1,
    "seed": 27,
    "checkpoint_name": "text_patch_gpt"
  },
  "tokenizer": {
    "type": "ae_bytes",
    "varlen_strategy": "padding"
  },
  "data": {
    "data_root": "../matformer_norepo/Minerva1024_lmdb",
    "batch_size": 8,
    "num_workers": 0
  },
  "save_dir": "./checkpoints",
  "wandb_project": "matformer",
  "wandb_run_name": "text_patch_gpt"
}
