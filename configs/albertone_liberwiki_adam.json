{
  "model_class": "BERTModel",
  "model_config": {
    "name": "Micro-Albertino-Liber-Wiki-1024-Adam3",
    "hidden_size": 768,
    "ffn_factor": 1.0,
    "num_hidden_layers": 28,
    "num_attention_heads": 12,
    "vocab_size": 32768,
    "bos_token_id": 1,
    "eos_token_id": 2,
    "pad_token_id": 0,
    "tie_word_embeddings": false,
    "rms_norm_eps": 1e-6,
    "attention_type": [],
    "sliding_window_size": 1024,
    "sliding_layers": [],
    "sliding_type": "disabled",
    "max_position_embeddings": 1024,
    "block_size_for_attention": 128,
    "compile_flexattn": false,
    "bias": false,
    "training_objective": "masked",
    "alibi": true,
    "is_causal": false,
    "attn_impl": "flash"
  },
  "training": {
      "optimizer": "adam",
      "lr_scheduling": true,
      "lr": 2e-4,
      "final_lr":1e-5,
      "weight_decay": 0.01,
      "scheduler": "custom",
      "warmup_steps": 15000,
      "hold_steps": 10000,
      "max_epochs": 1,
      "accumulate_grad_batches": 6,
      "seed": 27,
      "checkpoint_name": "albertone_liberwiki_1024_adam",
      "save_every_n_steps": 7500
  },
  "tokenizer": {
    "type": "huggingface",
    "pretrained_name": "sapienzanlp/Minerva-350M-base-v1.0",
    "varlen_strategy": "unpadding"
  },
  "data": {
    "data_root": "../matformer_norepo/Minerva1024_lmdb",
    "batch_size": 18,
    "num_workers": 1
  },
  "save_dir": "./checkpoints",
  "wandb_project": "Albertone",
  "wandb_run_name": "Albertone_liberwiki_1024_adam"
}
