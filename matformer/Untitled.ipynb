{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdbe1ef3-8924-4215-a7c2-689658556037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tok=AutoTokenizer.from_pretrained(\"mrinaldi/Gettone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcdcf0c4-20a8-44ed-a74d-9bd37d01fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasseVuota:\n",
    "    def __init__(self):\n",
    "        self.tokenizer=AutoTokenizer.from_pretrained(\"mrinaldi/Gettone\")\n",
    "classe=ClasseVuota()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d8fde9-5113-4439-909f-b4b9069c11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='mrinaldi/Gettone', vocab_size=32768, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[BOS]', 'eos_token': '[EOS]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"[BOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"[EOS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"[P]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"[T]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t9: AddedToken(\"[/T]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t10: AddedToken(\"[S0]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t11: AddedToken(\"[S1]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t12: AddedToken(\"[S2]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t13: AddedToken(\"[S3]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t14: AddedToken(\"[S4]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15: AddedToken(\"[S5]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1550be0a-cfbb-4a2b-949c-d3d8e7211667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdat import split_and_tokenize_by_nltk_sentences_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c52ce95-37e0-4568-9a23-74314e4abf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter=split_and_tokenize_by_nltk_sentences_aligned('italian',1024,classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32c8232c-14fe-4c53-b015-01bba80c5964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Empty sequence\n",
      "Error. too many indices for array: array is 1-dimensional, but 2 were indexed\n",
      "{'offset_mapping': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'tokens': [18703, 127], 'chunks': [(0, 2)]},\n",
       " {'tokens': [5269, 7666], 'chunks': [(0, 2)]},\n",
       " {'tokens': [], 'chunks': []}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.batched(['ciao','e allora',''])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
